{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sprite shape: (89400, 16, 16, 3)\n",
      "labels shape: (89400, 5)\n",
      "saved gif at imgani_run_wNone.gif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import tqdm\n",
    "from model.ContextUnet import ContextUnet\n",
    "from dataloader import spriteDataset, get_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from utils_draw import plot_sample\n",
    "\n",
    "def denoise(x, t, pred_noise, beta_t, alpha_t, alpha_bar_t, z=None):\n",
    "    if z is None:\n",
    "        z = torch.randn_like(x)\n",
    "    noise = torch.sqrt(beta_t[t]) * z\n",
    "    mean = (x - pred_noise * ((1 - alpha_t[t]) / (1 - alpha_bar_t[t]).sqrt())) / alpha_t[t].sqrt()\n",
    "    return mean + noise\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(n_sample, save_rate=20):\n",
    "    samples = torch.randn(n_sample, 3, picture_shape, picture_shape, device=device)\n",
    "    intermediate = []\n",
    "    for i in range(timesteps, 0, -1):\n",
    "        t = torch.tensor([i/timesteps])[:, None, None, None].to(device)\n",
    "        z = torch.randn_like(samples) if i > 1 else 0\n",
    "        epsilons = model(samples, t)\n",
    "        samples = denoise(samples, i, epsilons, beta_t, alpha_t, alpha_bar_t, z)\n",
    "        if i % save_rate == 0 or timesteps == i or i <= 8:\n",
    "            intermediate.append(samples.detach().cpu().numpy())\n",
    "    intermediate = np.stack(intermediate)\n",
    "    return samples, intermediate\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # parameters\n",
    "    timesteps = 500\n",
    "    beta = [1e-4, 0.02]\n",
    "    hidden_dim = 64\n",
    "    context_dim = 5\n",
    "    picture_shape = 16\n",
    "    batch_size = 128\n",
    "    epochs = 100\n",
    "    lr = 1e-3\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    # construct noise\n",
    "    beta_t = (beta[1] - beta[0]) * torch.linspace(0, 1, timesteps + 1, device=device) + beta[0]\n",
    "    alpha_t = 1 - beta_t\n",
    "    alpha_bar_t = torch.cumsum(alpha_t.log(), dim=0).exp()\n",
    "\n",
    "    # model\n",
    "    model = ContextUnet(in_channels=3, hidden_dim=hidden_dim, context_dim=context_dim, picture_shape=picture_shape).to(device)\n",
    "    model.load_state_dict(torch.load(\"model.pth\",weights_only=True))\n",
    "\n",
    "    # dataset\n",
    "    feature_file = \"/home/d3ac/Desktop/dataset/sprites_v1/sprites_1788_16x16.npy\"\n",
    "    label_file = \"/home/d3ac/Desktop/dataset/sprites_v1/sprite_labels_nc_1788_16x16.npy\"\n",
    "    dataset = spriteDataset(feature_file, label_file, transform=get_transforms())\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=7)\n",
    "\n",
    "    # test\n",
    "    model.eval()\n",
    "    plt.clf()\n",
    "    samples, intermediate_ddpm = sample(32)\n",
    "    animation_ddpm = plot_sample(intermediate_ddpm, 32, 4, 'img', \"ani_run\", None, save=True)\n",
    "    # HTML(animation_ddpm.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
